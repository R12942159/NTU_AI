{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r12942159/miniconda3/envs/AI/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from diffusers import StableDiffusionImg2ImgPipeline, AutoPipelineForImage2Image\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(img_dir):\n",
    "    img_paths = [os.path.join(img_dir, f\"{str(i).zfill(6)}.jpg\") for i in range(1, 101)]\n",
    "    images = [Image.open(path) for path in img_paths]\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phi4_model(phi4_model_name, custom_cache_dir):\n",
    "    processor = AutoProcessor.from_pretrained(phi4_model_name, trust_remote_code=True, cache_dir=custom_cache_dir)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        phi4_model_name, \n",
    "        device_map=\"cuda\", \n",
    "        torch_dtype=\"auto\", \n",
    "        trust_remote_code=True,\n",
    "        _attn_implementation='flash_attention_2',\n",
    "        cache_dir=custom_cache_dir,\n",
    "    ).cuda()\n",
    "\n",
    "    return processor, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_prompt(image, instruction, max_new_tokens, processor, model, phi4_model_name):\n",
    "    generation_config = GenerationConfig.from_pretrained(phi4_model_name)\n",
    "    inputs = processor(text=instruction, images=image, return_tensors='pt').to('cuda:0')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "        generated_ids = generated_ids[:, inputs['input_ids'].shape[1]:]\n",
    "        prompt = processor.batch_decode(generated_ids, \n",
    "                                        skip_special_tokens=True,\n",
    "                                        clean_up_tokenization_spaces=False,)\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_prompts(images, instruction, max_new_tokens, length, processor, model):\n",
    "    prompts = []\n",
    "    for i in tqdm(range(length)):\n",
    "        prompt = generate_text_prompt(\n",
    "            images[i],\n",
    "            instruction,\n",
    "            max_new_tokens, \n",
    "            processor, \n",
    "            model, \n",
    "            \"microsoft/Phi-4-multimodal-instruct\"\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prompts2json(prompts, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"prompts\": prompts}, f, indent=4)\n",
    "    \n",
    "    print(f\"Prompts successfully saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stable_diffusion(model_id, cache_dir):\n",
    "    # pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    #     model_id, \n",
    "    #     torch_dtype=torch.float16,\n",
    "    #     cache_dir=cache_dir,\n",
    "    #     safety_checker = None,\n",
    "    #     feature_extractor = None,\n",
    "    # ).to(\"cuda\")\n",
    "\n",
    "    pipe = AutoPipelineForImage2Image.from_pretrained(\n",
    "        \"stable-diffusion-v1-5/stable-diffusion-v1-5\", \n",
    "        torch_dtype=torch.float16, \n",
    "        variant=\"fp16\", \n",
    "        use_safetensors=False,\n",
    "        cache_dir=\"/home/r12942159/data_18TB\",\n",
    "        safety_checker = None,\n",
    "        feature_extractor = None,\n",
    "    )\n",
    "    pipe.enable_model_cpu_offload()\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompts(prompt_path):\n",
    "    with open(prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        prompts = json.load(f)\n",
    "\n",
    "    return prompts['prompts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, img_size=224):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform(image).permute(1, 2, 0).mul(255).byte().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stylized_images(pipe, prompt, image, strength=0.75, guidance_scale=7.5, seed=41):\n",
    "    image = Image.fromarray(resize_image(image, 512))\n",
    "    image = pipe(\n",
    "        prompt=prompt, \n",
    "        image=image, \n",
    "        strength=strength, \n",
    "        guidance_scale=guidance_scale, \n",
    "        generator=torch.manual_seed(seed),\n",
    "    ).images[0]\n",
    "    image = Image.fromarray(resize_image(image, 224))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(stylized_resize_images, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    for i, resized_image in enumerate(stylized_resize_images):\n",
    "        output_filename = f\"{i+1:06d}.jpg\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        resized_image.save(output_path)\n",
    "        \n",
    "        print(f\"Processed {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:26<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "phi4_processor, phi4_model = load_phi4_model(phi4_model_name = \"microsoft/Phi-4-multimodal-instruct\", \n",
    "                                             custom_cache_dir = \"/home/r12942159/data_18TB\")\n",
    "\n",
    "instruction = \"<|user|><|image_1|>Describe this person in the exact artistic style of Peanuts comics (Snoopy-style). Ensure the description makes the character look like they belong in a Charles Schulz comic strip. The person’s features—such as hair color, expression, and outfit—should remain the same, but they must be transformed into the signature Peanuts cartoon style: simple, bold outlines, flat colors, round heads, dot eyes, and minimal shading. The background should be minimalistic, similar to classic Peanuts comic settings. <|end|><|assistant|>\"\n",
    "# instruction = \"<|user|><|image_1|>Generate a prompt for a drawing in the style of Charles Schulz’s Snoopy comics. The prompt should describe a simple, cartoonish scene with bold outlines and minimal shading, using lighthearted and whimsical language.<|end|><|assistant|>\"\n",
    "# instruction = \"<|user|><|image_1|>Here are three examples of prompts that describe a Snoopy-style drawing: A happy beagle with big black ears sits on top of a red doghouse, looking at the stars. The style is simple, cartoonish, with clean black outlines and no shading. A small bird with tiny wings and a tuft of feathers on its head flutters near a dog, both smiling in a minimal, newspaper comic strip style. A relaxed dog, lying on his back with a dreamy expression, while a tiny yellow bird perches on his nose. The lines are hand-drawn, expressive, and playful. Now, generate a new prompt in the same style. <|end|><|assistant|>\"\n",
    "instruction = \"<|user|><|image_1|>Generate a text prompt for an AI art model that produces an illustration in the style of Snoopy comics. The scene should contain a dog and a bird, use a limited color palette (black, white, and simple solid colors), and be drawn with thick, hand-drawn outlines. The mood should be lighthearted and whimsical. <|end|><|assistant|>\"\n",
    "images = read_images(img_dir = '/home/r12942159/NTU_AI/Hw1/content_image/')\n",
    "\n",
    "prompts = generate_text_prompts(\n",
    "    images, \n",
    "    instruction,\n",
    "    75, \n",
    "    len(images), \n",
    "    phi4_processor, \n",
    "    phi4_model,\n",
    ")\n",
    "# save_prompts2json(prompts, 'Task2-2_prompts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 5/5 [00:01<00:00,  2.67it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "pipe = load_stable_diffusion(\n",
    "    \"stable-diffusion-v1-5/stable-diffusion-v1-5\", \n",
    "    \"/home/r12942159/data_18TB\",\n",
    ")\n",
    "\n",
    "images = read_images(img_dir = '/home/r12942159/NTU_AI/Hw1/content_image/')\n",
    "prompts = read_prompts(\"/home/r12942159/NTU_AI/Hw1/Task2-2_prompts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylized_resize_images = [generate_stylized_images(pipe, prompts[i], images[i], strength=0.75, guidance_scale=7.5, seed=41) for i in range(len(images))]\n",
    "save_images(stylized_resize_images, '/home/r12942159/NTU_AI/Hw1/hw1_Task2-2_output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate profile photo with snoopy style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi4_processor, phi4_model = load_phi4_model(phi4_model_name = \"microsoft/Phi-4-multimodal-instruct\", \n",
    "                                             custom_cache_dir = \"/home/r12942159/data_18TB\")\n",
    "\n",
    "img = Image.open('/home/r12942159/NTU_AI/Hw1/profile_photo.jpg')\n",
    "\n",
    "instruction = \"<|user|><|image_1|>Describe this person in the exact artistic style of Peanuts comics (Snoopy-style). Ensure the description makes the character look like they belong in a Charles Schulz comic strip. The person’s features—such as hair color, expression, and outfit—should remain the same, but they must be transformed into the signature Peanuts cartoon style: simple, bold outlines, flat colors, round heads, dot eyes, and minimal shading. The background should be minimalistic, similar to classic Peanuts comic settings. <|end|><|assistant|>\"\n",
    "generation_config = GenerationConfig.from_pretrained(\"microsoft/Phi-4-multimodal-instruct\")\n",
    "inputs = phi4_processor(text=instruction, images=img, return_tensors='pt').to('cuda:0')\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_ids = phi4_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "    generated_ids = generated_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    prompt = phi4_processor.batch_decode(generated_ids, \n",
    "                                    skip_special_tokens=True,\n",
    "                                    clean_up_tokenization_spaces=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['focus on the character . the overall style would be simple , bold , and cartoonish , fitting the peanuts aesthetic .']\n",
      "100%|██████████| 47/47 [00:02<00:00, 17.27it/s]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('/home/r12942159/NTU_AI/Hw1/Task2-2_profile_photo1.jpg')\n",
    "prompt = 'In the Peanuts comic style, the person would have a round head with short, dark hair. The expression would be a simple, neutral look, with a slight hint of a smile. The outfit would be a white shirt with blue horizontal stripes, but the colors would be more solid and less detailed. The background would be minimalistic, with a plain white backdrop to keep the focus on the character. The overall style would be simple, bold, and cartoonish, fitting the Peanuts aesthetic.'\n",
    "generate_stylized_images(pipe, prompt, img, 0.95, 10.5, 37).save('/home/r12942159/NTU_AI/Hw1/Task2-2_profile_snoopy.jpg')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
