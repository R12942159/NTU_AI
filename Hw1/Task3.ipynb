{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r12942159/miniconda3/envs/AI/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from diffusers import StableDiffusionImg2ImgPipeline, AutoPipelineForImage2Image\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(img_dir):\n",
    "    img_paths = [os.path.join(img_dir, f\"{str(i).zfill(6)}.jpg\") for i in range(1, 101)]\n",
    "    images = [Image.open(path) for path in img_paths]\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phi4_model(phi4_model_name, custom_cache_dir):\n",
    "    processor = AutoProcessor.from_pretrained(phi4_model_name, trust_remote_code=True, cache_dir=custom_cache_dir)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        phi4_model_name, \n",
    "        device_map=\"cuda\", \n",
    "        torch_dtype=\"auto\", \n",
    "        trust_remote_code=True,\n",
    "        _attn_implementation='flash_attention_2',\n",
    "        cache_dir=custom_cache_dir,\n",
    "    ).cuda()\n",
    "\n",
    "    return processor, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_prompt(image, max_new_tokens, processor, model, phi4_model_name):\n",
    "    instruction = \"<|user|><|image_1|>Describe this person in the exact artistic style of Peanuts comics (Snoopy-style). Ensure the description makes the character look like they belong in a Charles Schulz comic strip. The person’s features—such as hair color, expression, and outfit—should remain the same, but they must be transformed into the signature Peanuts cartoon style: simple, bold outlines, flat colors, round heads, dot eyes, and minimal shading. The background should be minimalistic, similar to classic Peanuts comic settings. <|end|><|assistant|>\"\n",
    "    generation_config = GenerationConfig.from_pretrained(phi4_model_name)\n",
    "    inputs = processor(text=instruction, images=image, return_tensors='pt').to('cuda:0')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "        generated_ids = generated_ids[:, inputs['input_ids'].shape[1]:]\n",
    "        prompt = processor.batch_decode(generated_ids, \n",
    "                                        skip_special_tokens=True,\n",
    "                                        clean_up_tokenization_spaces=False,)\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_prompts(images, max_new_tokens, length, processor, model):\n",
    "    prompts = []\n",
    "    for i in tqdm(range(length)):\n",
    "        prompt = generate_text_prompt(\n",
    "            images[i],\n",
    "            max_new_tokens, \n",
    "            processor, \n",
    "            model, \n",
    "            \"microsoft/Phi-4-multimodal-instruct\"\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prompts2json(prompts, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"prompts\": prompts}, f, indent=4)\n",
    "    \n",
    "    print(f\"Prompts successfully saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stable_diffusion(model_id, cache_dir):\n",
    "    # pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    #     model_id, \n",
    "    #     torch_dtype=torch.float16,\n",
    "    #     cache_dir=cache_dir,\n",
    "    #     safety_checker = None,\n",
    "    #     feature_extractor = None,\n",
    "    # ).to(\"cuda\")\n",
    "\n",
    "    pipe = AutoPipelineForImage2Image.from_pretrained(\n",
    "        \"stable-diffusion-v1-5/stable-diffusion-v1-5\", \n",
    "        torch_dtype=torch.float16, \n",
    "        variant=\"fp16\", \n",
    "        use_safetensors=False,\n",
    "        cache_dir=\"/home/r12942159/data_18TB\",\n",
    "        safety_checker = None,\n",
    "        feature_extractor = None,\n",
    "    )\n",
    "    pipe.enable_model_cpu_offload()\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompts(prompt_path):\n",
    "    with open(prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        prompts = json.load(f)\n",
    "\n",
    "    return prompts['prompts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform(image).permute(1, 2, 0).mul(255).byte().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stylized_images(pipe, prompt, image, strength=0.75, guidance_scale=7.5, seed=41):\n",
    "    image = Image.fromarray(resize_image(image))\n",
    "    image = pipe(\n",
    "        prompt=prompt, \n",
    "        image=image, \n",
    "        strength=strength, \n",
    "        guidance_scale=guidance_scale, \n",
    "        generator=torch.manual_seed(seed),\n",
    "    ).images[0]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(stylized_resize_images, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    for i, resized_image in enumerate(stylized_resize_images):\n",
    "        output_filename = f\"{i+1:06d}.jpg\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        resized_image.save(output_path)\n",
    "        \n",
    "        print(f\"Processed {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi4_processor, phi4_model = load_phi4_model(phi4_model_name = \"microsoft/Phi-4-multimodal-instruct\", \n",
    "                                             custom_cache_dir = \"/home/r12942159/data_18TB\")\n",
    "\n",
    "images = read_images(img_dir = '/home/r12942159/NTU_AI/Hw1/content_image/')\n",
    "\n",
    "prompts = generate_text_prompts(\n",
    "    images, \n",
    "    75, \n",
    "    len(images), \n",
    "    phi4_processor, \n",
    "    phi4_model,\n",
    ")\n",
    "save_prompts2json(prompts, 'Task2-2_prompts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00,  7.65it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "pipe = load_stable_diffusion(\n",
    "    \"stable-diffusion-v1-5/stable-diffusion-v1-5\", \n",
    "    \"/home/r12942159/data_18TB\",\n",
    ")\n",
    "\n",
    "images = read_images(img_dir = '/home/r12942159/NTU_AI/Hw1/content_image/')\n",
    "prompts = read_prompts(\"/home/r12942159/NTU_AI/Hw1/Task2-2_prompts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 000001.jpg\n",
      "Processed 000002.jpg\n",
      "Processed 000003.jpg\n",
      "Processed 000004.jpg\n",
      "Processed 000005.jpg\n",
      "Processed 000006.jpg\n",
      "Processed 000007.jpg\n",
      "Processed 000008.jpg\n",
      "Processed 000009.jpg\n",
      "Processed 000010.jpg\n",
      "Processed 000011.jpg\n",
      "Processed 000012.jpg\n",
      "Processed 000013.jpg\n",
      "Processed 000014.jpg\n",
      "Processed 000015.jpg\n",
      "Processed 000016.jpg\n",
      "Processed 000017.jpg\n",
      "Processed 000018.jpg\n",
      "Processed 000019.jpg\n",
      "Processed 000020.jpg\n",
      "Processed 000021.jpg\n",
      "Processed 000022.jpg\n",
      "Processed 000023.jpg\n",
      "Processed 000024.jpg\n",
      "Processed 000025.jpg\n",
      "Processed 000026.jpg\n",
      "Processed 000027.jpg\n",
      "Processed 000028.jpg\n",
      "Processed 000029.jpg\n",
      "Processed 000030.jpg\n",
      "Processed 000031.jpg\n",
      "Processed 000032.jpg\n",
      "Processed 000033.jpg\n",
      "Processed 000034.jpg\n",
      "Processed 000035.jpg\n",
      "Processed 000036.jpg\n",
      "Processed 000037.jpg\n",
      "Processed 000038.jpg\n",
      "Processed 000039.jpg\n",
      "Processed 000040.jpg\n",
      "Processed 000041.jpg\n",
      "Processed 000042.jpg\n",
      "Processed 000043.jpg\n",
      "Processed 000044.jpg\n",
      "Processed 000045.jpg\n",
      "Processed 000046.jpg\n",
      "Processed 000047.jpg\n",
      "Processed 000048.jpg\n",
      "Processed 000049.jpg\n",
      "Processed 000050.jpg\n",
      "Processed 000051.jpg\n",
      "Processed 000052.jpg\n",
      "Processed 000053.jpg\n",
      "Processed 000054.jpg\n",
      "Processed 000055.jpg\n",
      "Processed 000056.jpg\n",
      "Processed 000057.jpg\n",
      "Processed 000058.jpg\n",
      "Processed 000059.jpg\n",
      "Processed 000060.jpg\n",
      "Processed 000061.jpg\n",
      "Processed 000062.jpg\n",
      "Processed 000063.jpg\n",
      "Processed 000064.jpg\n",
      "Processed 000065.jpg\n",
      "Processed 000066.jpg\n",
      "Processed 000067.jpg\n",
      "Processed 000068.jpg\n",
      "Processed 000069.jpg\n",
      "Processed 000070.jpg\n",
      "Processed 000071.jpg\n",
      "Processed 000072.jpg\n",
      "Processed 000073.jpg\n",
      "Processed 000074.jpg\n",
      "Processed 000075.jpg\n",
      "Processed 000076.jpg\n",
      "Processed 000077.jpg\n",
      "Processed 000078.jpg\n",
      "Processed 000079.jpg\n",
      "Processed 000080.jpg\n",
      "Processed 000081.jpg\n",
      "Processed 000082.jpg\n",
      "Processed 000083.jpg\n",
      "Processed 000084.jpg\n",
      "Processed 000085.jpg\n",
      "Processed 000086.jpg\n",
      "Processed 000087.jpg\n",
      "Processed 000088.jpg\n",
      "Processed 000089.jpg\n",
      "Processed 000090.jpg\n",
      "Processed 000091.jpg\n",
      "Processed 000092.jpg\n",
      "Processed 000093.jpg\n",
      "Processed 000094.jpg\n",
      "Processed 000095.jpg\n",
      "Processed 000096.jpg\n",
      "Processed 000097.jpg\n",
      "Processed 000098.jpg\n",
      "Processed 000099.jpg\n",
      "Processed 000100.jpg\n"
     ]
    }
   ],
   "source": [
    "stylized_resize_images = [generate_stylized_images(pipe, prompts[i], images[i], strength=0.75, guidance_scale=7.5, seed=41) for i in range(len(images))]\n",
    "save_images(stylized_resize_images, '/home/r12942159/NTU_AI/Hw1/hw1_Task2-2_output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate profile photo with snoopy style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi4_processor, phi4_model = load_phi4_model(phi4_model_name = \"microsoft/Phi-4-multimodal-instruct\", \n",
    "                                             custom_cache_dir = \"/home/r12942159/data_18TB\")\n",
    "\n",
    "img = Image.open('/home/r12942159/NTU_AI/Hw1/profile_photo.jpg')\n",
    "\n",
    "instruction = \"<|user|><|image_1|>Describe this person in the exact artistic style of Peanuts comics (Snoopy-style). Ensure the description makes the character look like they belong in a Charles Schulz comic strip. The person’s features—such as hair color, expression, and outfit—should remain the same, but they must be transformed into the signature Peanuts cartoon style: simple, bold outlines, flat colors, round heads, dot eyes, and minimal shading. The background should be minimalistic, similar to classic Peanuts comic settings. <|end|><|assistant|>\"\n",
    "generation_config = GenerationConfig.from_pretrained(\"microsoft/Phi-4-multimodal-instruct\")\n",
    "inputs = phi4_processor(text=instruction, images=img, return_tensors='pt').to('cuda:0')\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_ids = phi4_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "    generated_ids = generated_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    prompt = phi4_processor.batch_decode(generated_ids, \n",
    "                                    skip_special_tokens=True,\n",
    "                                    clean_up_tokenization_spaces=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['focus on the character . the overall style would be simple , bold , and cartoonish , fitting the peanuts aesthetic .']\n",
      "100%|██████████| 42/42 [00:00<00:00, 79.83it/s]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('/home/r12942159/NTU_AI/Hw1/Task2-2_profile_photo1.jpg')\n",
    "prompt = 'In the Peanuts comic style, the person would have a round head with short, dark hair. The expression would be a simple, neutral look, with a slight hint of a smile. The outfit would be a white shirt with blue horizontal stripes, but the colors would be more solid and less detailed. The background would be minimalistic, with a plain white backdrop to keep the focus on the character. The overall style would be simple, bold, and cartoonish, fitting the Peanuts aesthetic.'\n",
    "generate_stylized_images(pipe, prompt, img, 0.85, 10.5, 41).save('/home/r12942159/NTU_AI/Hw1/Task2-2_profile_snoopy.jpg')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
